# 第7章：我们能在地球上存活吗？

## 概述

本章发出严峻警告：地球面临多重生存威胁。《原子科学家公报》的末日时钟在2018年调至午夜前2分钟，接近历史最危险时刻。霍金列举了核战争、气候变化、小行星撞击、人口爆炸等威胁，认为在未来1000年内某种灾难几乎不可避免。他呼吁科学家履行责任，警告公众和领导人；批评政客否认气候变化；提出唯一出路是太空殖民。霍金还讨论了未来科技发展：基因工程将改造人类，AI将超越人类智能，知识增长速度远超生物进化。结论悲观但充满希望：如果不离开地球，人类有被歼灭的危险；但我们的探索天性和科技进步给了我们生存机会。

## 核心威胁

### 1. 核战争

- 最大威胁，即使冷战结束
- 足够武器多次毁灭全人类
- 新核国家增加不稳定性
- 事故或恐怖分子获得武器的风险

### 2. 气候变化（最紧迫）

- 人为造成，所有人责任
- 可能变成自持续过程
- **失控场景**：
  - 冰盖融化→减少反射→温度升高
  - 雨林毁灭→失去CO₂吸收
  - 海水升温→释放大量CO₂
  - 可能变成金星气候：250°C，硫酸雨
  - 人类生命无法维持

### 3. 小行星撞击

- 无法防御
- 上次6600万年前，恐龙灭绝
- 平均每2000万年一次重大撞击
- "绝不是科幻，是物理定律和概率保证"

### 4. 人口爆炸

- 从10亿→76亿
- 指数增长不可持续
- 2600年：擦肩摩踵，地球发红热

### 5. 其他威胁

- 疾病、战争、饥荒
- 缺水、物种毁灭
- 森林砍伐、资源枯竭

## 末日时钟的警告

### 历史

- 1947年开始：午夜前7分钟
- 1950年代冷战开始时最接近
- 2018年：午夜前2分钟（历史第二近）

### 奥本海默的反思（1945）

> "现在我成为死神，世界的毁灭者。"（《博伽梵歌》）

### 为何拨近

- 特朗普当选
- 政治不稳定
- 否认气候变化
- 核威胁增加

## 科学家的责任

### 霍金的呼吁

1. 向公众宣传危险
2. 提醒领导人
3. 理解核武器毁灭性
4. 了解气候系统受影响
5. 作为世界公民分享知识

### 紧迫行动

- 淘汰核武器
- 防止气候进一步恶化
- 超越《京都议定书》
- 立即减少碳排放
- "我们拥有技术，只需要政治意愿"

## 政治现实

### 问题

- 政客否认人为气候变化
- 或否认人类能力扭转它
- 经验有限的民粹政客
- 莽撞或恶意力量增加

### 霍金的批评

- 世界比记忆中更不稳定
- 人们经济和社会被抛弃
- 转向经验有限的政客
- 危机中决定能力未受考验

## 未来科技发展

### 知识增长困境

**指数增长不可持续**：

- 目前每年5万本新书（1000亿比特）
- 物理学每秒10篇论文（到2600年）
- 无人有时间阅读
- 18世纪：有人能读遍所有书
- 现在：读完国家图书馆需数万年

**人脑演化跟不上**：

- 信息积累：50年
- 大脑演化：数十万年
- 必须专注越来越狭窄领域

### 基因工程革命

**现状**：

- 1万年DNA变化很小
- 下个千年完全重新设计
- 已绘制"生命之书"

**能力**：

- 修复遗传缺陷（囊性纤维化、肌营养不良）
- 改善智力、攻击性本能
- 延长寿命、增强记忆
- 抗病能力

**后果**：

- 无法禁止（有人会尝试）
- 超人出现
- 未改善人类无法竞争
- 可能死绝或被边缘化
- 自我设计生物不断完善

### AI超越人类

**摩尔定律**：

- 速度和复杂性每18个月翻倍
- 100年内某时刻超越人类
- 将设计更智能AI
- 递归改进

**当前电脑**：

- 不如蚯蚓大脑复杂
- 无智能迹象
- 但快速进步中

**未来**：

- 复杂电子电路→智能
- 会设计更复杂AI
- 生物和电子领域复杂性迅速增长

## 理论物理的未来

### 完备理论的追求

**目标**：

- 统一量子力学和广义相对论
- 解决无限能量问题
- 闭合粒子环的抵消

**霍金预测（1980）**：

- 当时：50%机会20年内发现
- 现在：仍然遥远
- 但相信终能达到

### 普朗克长度

- 最小尺度：10⁻³⁵米
- 俄罗斯娃娃的最小娃娃
- 无法用加速器探测
- 依靠数学美和一致性

### 复杂性无限

- 终极理论不限制复杂性
- 下个千年最重要发展在复杂性中
- 永远不会达到静态《星际迷航》式未来

## DNA与AI的竞赛

### DNA信息增长（生物进化）

- 最早20亿年：每百年1比特
- 近几百万年：每年1比特
- 人类DNA约1亿比特（50本《哈利波特》）

### 书籍信息增长（外部传输）

- 国家图书馆：10万亿比特（DNA的10万倍）
- 每年5万本新书：500亿比特
- 增速是DNA的数百万到数十亿倍

### AI增长

- 指数增长中
- 已开始放缓
- 但将达到人类大脑复杂性
- 之后可能爆炸式发展

## 金句

1. **奥本海默的反思**：

   > "现在我成为死神，世界的毁灭者。"

2. **关于时间**：

   > "作为一个21岁即被告知只有5年可活的人，在2018年已经76岁了——我是在另一种意义上的时间专家，亲身经历的专家。"

3. **关于气候灾难**：

   > "可能使我们的气候变得像金星的气候，酷热和下硫酸雨，温度为250摄氏度。人类的生命将不能维持。"

4. **关于殖民必要性**：

   > "哥伦布于1492年发现了新世界时这么做了，但现在没有新世界。附近没有乌托邦。我们的空间已经不多了，唯一可去的地方是其他世界。"

5. **关于不可避免性**：

   > "我认为以下灾难几乎是不可避免的，无论是核对抗还是环境灾难将在接下来的1000年中的某一时刻使地球瘫痪，1000年用地质年代衡量只是眨眼瞬间。"

6. **关于探索天性**：

   > "我们天生就是探险家，受着好奇心的激励。这是一种独特的人类素质。"

7. **关于离开地球**：
   > "我确信人类需要离开地球。如果我们留下来，就有被歼灭的危险。"

## 与其他章节联系

- **第3章**：知识外部传输，自我设计进化
- **第6章**：物种消亡，文明自我毁灭可能
- **第8章**（下一章）：太空殖民的必要性和方案
- **第9章**：AI威胁和机遇
- **第10章**：人类选择和责任

## 来源信息

- **来源文件**：`_7_Will_we_survive_on_Earth_我们能在地球上存活吗.md`
- **章节**：第7章，共10章
